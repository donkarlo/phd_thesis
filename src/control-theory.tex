\chapter{Control theory}
\textbf{Feedback theory}
Feedback theory is a foundational concept in control theory that explains how systems regulate their behavior through feedback loops. It provides a mathematical framework for monitoring outputs, comparing them to desired targets, and making adjustments to minimize errors. This theory ensures stability, robustness, and adaptability in dynamic systems, allowing them to maintain equilibrium and respond to disturbances effectively. Feedback theory is widely applied in robotics for tasks such as stabilization and trajectory control, where sensors provide real-time data to refine motor commands. Its principles are crucial for designing both biological and artificial systems that integrate perception, action, and learning. \cite{sutton-2018-reinforcement-learning} \cite{rao-1999-predictive-coding}


\section{Overview of Control Systems}

\subsection{Open-Loop Control Systems}
Open-loop control systems operate without feedback, relying on predefined commands to control the robot's actions. These systems are straightforward to implement and suitable for predictable tasks where system dynamics and disturbances are negligible. For example, in robotics, an open-loop system might control a conveyor belt or move a robotic arm to a fixed position without considering external influences. While cost-effective, these systems lack the ability to correct errors caused by changes in the environment or system inaccuracies, making them unsuitable for dynamic tasks.

\subsection{Closed-Loop (Feedback) Control Systems}
Closed-loop control systems use feedback from sensors to adjust the robot's actions in real-time. This feedback loop ensures that the desired outcomes are achieved even in the presence of disturbances or uncertainties. For instance, a balancing robot like a Segway uses feedback from gyroscopes to maintain its balance, or a drone adjusts its altitude based on barometric pressure readings. These systems are accurate and robust but require sensors and additional computational power, increasing system complexity and cost.

\subsection{Proportional-Integral-Derivative (PID) Control}
PID control is a fundamental closed-loop control algorithm that adjusts system outputs based on the proportional, integral, and derivative of the error signal. It is widely used for tasks requiring precise control, such as maintaining the position or speed of robotic arms or ensuring drones hover steadily in midair. While PID controllers are easy to implement and tune for linear systems, they can struggle with highly dynamic or nonlinear systems where advanced control techniques may be required.

\subsection{Adaptive Control}
Adaptive control dynamically adjusts its parameters to maintain optimal performance under changing conditions. This type of control is ideal for robots operating in unpredictable environments, such as drones dealing with fluctuating wind conditions. For example, an adaptive controller can modify a drone's flight parameters in real-time to maintain stability and performance as the payload or environmental factors change. While powerful, designing and implementing adaptive control systems can be complex and computationally demanding.

\subsection{Optimal Control}
Optimal control focuses on minimizing or maximizing a specific performance criterion, such as energy consumption, time, or trajectory accuracy, over a given system trajectory. In robotics, optimal control might be used to plan efficient paths for robotic arms or drones to minimize travel time and energy use. For example, drones tasked with area surveillance can optimize their flight paths to maximize coverage with minimal battery consumption. While achieving high performance, these systems require accurate models and significant computational resources.

\subsection{Model Predictive Control (MPC)}
Model Predictive Control predicts future states of the system using a model and optimizes control inputs over a finite time horizon to meet constraints and objectives. This approach is particularly useful for complex and multivariable robotic systems. For instance, autonomous drones can use MPC to plan collision-free trajectories in dynamic environments, taking into account sensor data from LiDAR and cameras. Although MPC provides excellent performance in constrained systems, its computational requirements can be a limitation for fast-moving robots.

\subsection{Robust Control}
Robust control ensures system stability and performance even in the presence of uncertainties and disturbances. This type of control is commonly used in industrial robots or drones operating under varying environmental conditions, such as strong winds. For example, a robust controller for a drone would maintain stability and precise operation despite model inaccuracies or sensor noise. While highly reliable, robust control systems often involve conservative designs and require detailed modeling efforts.

\subsection{Nonlinear Control}
Nonlinear control addresses systems where linear assumptions do not hold, such as robotic arms with flexible joints or drones performing aerobatic maneuvers. Nonlinear controllers use specialized techniques to handle complex dynamics, enabling robots to operate effectively in challenging conditions. For instance, a nonlinear controller might stabilize a humanoid robot walking on uneven terrain or a drone performing tight turns at high speeds. Designing nonlinear control systems is mathematically challenging but essential for advanced robotics.

\subsection{Learning-Based Control}
Learning-based control integrates machine learning algorithms to optimize control strategies based on data or experience. Robots, such as drones, can learn to navigate dynamic environments by adapting their flight controllers using data from sensors like IMU, GPS, and cameras. For example, a drone might learn to avoid obstacles in a cluttered environment by combining reinforcement learning with traditional control techniques. This approach is highly effective for complex and evolving tasks but requires extensive training data and computational power.

\subsection{Hybrid Control Systems}
Hybrid control systems combine continuous control methods with discrete decision-making processes, such as finite state machines. These systems are ideal for robots with mixed dynamics, such as drones switching between hover and travel modes or robotic arms transitioning between different operational states. For example, a hybrid controller could manage a drone's transition from autonomous navigation to manual control in emergency scenarios. While versatile, hybrid systems require careful integration of discrete and continuous control elements.

\subsection{H-Infinity Control}
H-Infinity control is a robust control approach that minimizes the worst-case gain of disturbances in the system. This method ensures reliable operation under extreme uncertainties, making it ideal for high-stakes applications such as aerospace robotics. For instance, an H-Infinity controller might stabilize a space robot in the presence of unpredictable gravitational forces or disturbances. While effective in maintaining stability, this approach requires advanced mathematical design and analysis.

\subsection{Fuzzy Logic Control}
Fuzzy logic control uses degrees of truth rather than binary logic to handle uncertainty and imprecision in control systems. This method is well-suited for applications where precise models are unavailable. For example, fuzzy logic can control a robotic vacuum cleaner navigating cluttered rooms or a drone making smooth altitude adjustments. While intuitive and effective in many scenarios, fuzzy logic systems can sometimes lack precision compared to traditional control methods.

\section{Questions}

Are there neural control theories?